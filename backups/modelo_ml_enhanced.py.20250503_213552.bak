import numpy as np
import re
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
import json
import os
import pickle
import nltk
import logging
import random
from collections import defaultdict
from typing import Dict, List, Tuple, Optional, Union, Any
import mysql.connector
from mysql.connector import Error

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Descargar recursos de NLTK necesarios si no existen
try:
    nltk.data.find('corpora/stopwords')
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('stopwords')
    nltk.download('punkt')
    nltk.download('wordnet')

class TextDataset(Dataset):
    def __init__(self, entradas, salidas, tokenizer):
        self.entradas = entradas
        self.salidas = salidas
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.entradas)

    def __getitem__(self, idx):
        # Vectorize the input text
        entrada = self.tokenizer.transform([self.entradas[idx]]).toarray()[0]
        
        # Ensure consistent vector size
        if len(entrada) < 5000:
            entrada = np.pad(entrada, (0, 5000 - len(entrada)), 'constant')
        elif len(entrada) > 5000:
            entrada = entrada[:5000]

        salida = float(self.salidas[idx])
        return torch.tensor(entrada, dtype=torch.float32), torch.tensor(salida, dtype=torch.float32)

class EnhancedContenidoEvaluator(nn.Module):
    """Modelo mejorado para evaluar diferentes tipos de contenido con arquitectura más profunda"""
    def __init__(self, input_dim=5000, hidden_dim=768, output_dim=1):
        super(EnhancedContenidoEvaluator, self).__init__()
        # Arquitectura más profunda con residual connections
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.bn1 = nn.BatchNorm1d(hidden_dim)
        self.dropout1 = nn.Dropout(0.3)
        
        # Bloque residual 1
        self.res1_fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.res1_bn1 = nn.BatchNorm1d(hidden_dim)
        self.res1_dropout = nn.Dropout(0.3)
        self.res1_fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.res1_bn2 = nn.BatchNorm1d(hidden_dim)
        
        # Bloque residual 2
        self.res2_fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.res2_bn1 = nn.BatchNorm1d(hidden_dim)
        self.res2_dropout = nn.Dropout(0.3)
        self.res2_fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.res2_bn2 = nn.BatchNorm1d(hidden_dim)
        
        # Capa de reducción
        self.fc_reduce = nn.Linear(hidden_dim, hidden_dim // 2)
        self.bn_reduce = nn.BatchNorm1d(hidden_dim // 2)
        self.dropout_reduce = nn.Dropout(0.2)
        
        # Múltiples cabezas para diferentes criterios de evaluación
        self.head_relevancia = nn.Linear(hidden_dim // 2, 1)
        self.head_profundidad = nn.Linear(hidden_dim // 2, 1)
        self.head_claridad = nn.Linear(hidden_dim // 2, 1)
        self.head_originalidad = nn.Linear(hidden_dim // 2, 1)
        self.head_global = nn.Linear(hidden_dim // 2, 1)
        
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Capa inicial
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout1(x)
        
        # Bloque residual 1
        residual = x
        out = self.res1_fc1(x)
        out = self.res1_bn1(out)
        out = self.relu(out)
        out = self.res1_dropout(out)
        out = self.res1_fc2(out)
        out = self.res1_bn2(out)
        out += residual  # Conexión residual
        out = self.relu(out)
        
        # Bloque residual 2
        residual = out
        out = self.res2_fc1(out)
        out = self.res2_bn1(out)
        out = self.relu(out)
        out = self.res2_dropout(out)
        out = self.res2_fc2(out)
        out = self.res2_bn2(out)
        out += residual  # Conexión residual
        out = self.relu(out)
        
        # Reducción de dimensionalidad
        x = self.fc_reduce(out)
        x = self.bn_reduce(x)
        x = self.relu(x)
        x = self.dropout_reduce(x)
        
        # Salidas para cada criterio (escaladas a 0-10)
        relevancia = self.sigmoid(self.head_relevancia(x)) * 10
        profundidad = self.sigmoid(self.head_profundidad(x)) * 10
        claridad = self.sigmoid(self.head_claridad(x)) * 10
        originalidad = self.sigmoid(self.head_originalidad(x)) * 10
        
        # Calificación global
        global_score = self.sigmoid(self.head_global(x)) * 10
        
        return {
            'relevancia': relevancia,
            'profundidad': profundidad,
            'claridad': claridad,
            'originalidad': originalidad,
            'global': global_score
        }

class EnhancedCodigoEvaluator(nn.Module):
    """Modelo especializado mejorado para evaluar código de programación"""
    def __init__(self, input_dim=5000, hidden_dim=768, output_dim=1):
        super(EnhancedCodigoEvaluator, self).__init__()
        # Arquitectura más profunda con residual connections
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.bn1 = nn.BatchNorm1d(hidden_dim)
        self.dropout1 = nn.Dropout(0.3)
        
        # Bloque residual 1
        self.res1_fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.res1_bn1 = nn.BatchNorm1d(hidden_dim)
        self.res1_dropout = nn.Dropout(0.3)
        self.res1_fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.res1_bn2 = nn.BatchNorm1d(hidden_dim)
        
        # Bloque residual 2
        self.res2_fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.res2_bn1 = nn.BatchNorm1d(hidden_dim)
        self.res2_dropout = nn.Dropout(0.3)
        self.res2_fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.res2_bn2 = nn.BatchNorm1d(hidden_dim)
        
        # Capa de reducción
        self.fc_reduce = nn.Linear(hidden_dim, hidden_dim // 2)
        self.bn_reduce = nn.BatchNorm1d(hidden_dim // 2)
        self.dropout_reduce = nn.Dropout(0.2)
        
        # Cabezas específicas para evaluación de código
        self.head_funcionalidad = nn.Linear(hidden_dim // 2, 1)
        self.head_eficiencia = nn.Linear(hidden_dim // 2, 1)
        self.head_estilo = nn.Linear(hidden_dim // 2, 1)
        self.head_documentacion = nn.Linear(hidden_dim // 2, 1)
        self.head_global = nn.Linear(hidden_dim // 2, 1)
        
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Capa inicial
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout1(x)
        
        # Bloque residual 1
        residual = x
        out = self.res1_fc1(x)
        out = self.res1_bn1(out)
        out = self.relu(out)
        out = self.res1_dropout(out)
        out = self.res1_fc2(out)
        out = self.res1_bn2(out)
        out += residual  # Conexión residual
        out = self.relu(out)
        
        # Bloque residual 2
        residual = out
        out = self.res2_fc1(out)
        out = self.res2_bn1(out)
        out = self.relu(out)
        out = self.res2_dropout(out)
        out = self.res2_fc2(out)
        out = self.res2_bn2(out)
        out += residual  # Conexión residual
        out = self.relu(out)
        
        # Reducción de dimensionalidad
        x = self.fc_reduce(out)
        x = self.bn_reduce(x)
        x = self.relu(x)
        x = self.dropout_reduce(x)
        
        # Salidas para cada criterio (escaladas a 0-10)
        funcionalidad = self.sigmoid(self.head_funcionalidad(x)) * 10
        eficiencia = self.sigmoid(self.head_eficiencia(x)) * 10
        estilo = self.sigmoid(self.head_estilo(x)) * 10
        documentacion = self.sigmoid(self.head_documentacion(x)) * 10
        
        # Calificación global
        global_score = self.sigmoid(self.head_global(x)) * 10
        
        return {
            'funcionalidad': funcionalidad,
            'eficiencia': eficiencia,
            'estilo': estilo,
            'documentacion': documentacion,
            'global': global_score
        }

class DummyModel:
    """Modelo dummy que siempre devuelve un valor predeterminado."""
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.logger.info("Inicializando modelo dummy")
    
    def eval(self):
        """Método para compatibilidad con PyTorch."""
        return self
    
    def __call__(self, *args, **kwargs):
        """Devuelve un valor predeterminado."""
        return torch.tensor([[0.75]], dtype=torch.float32)  # Valor de dificultad media
    
    def to(self, device):
        """Método para compatibilidad con PyTorch."""
        return self

class EnhancedModeloEvaluacionInteligente:
    """
    Modelo integrado mejorado para evaluación inteligente de contenido.
    Detecta automáticamente el tipo de contenido y aplica el evaluador adecuado.
    """
    def __init__(self, db_config=None, use_sbert=False):
        """
        Inicializa el modelo de evaluación inteligente mejorado.
        
        Args:
            db_config: Configuración para la conexión a la base de datos
            use_sbert: Si es True, utiliza modelos SBERT para análisis semántico profundo
        """
        # Configurar stopwords en español
        self.spanish_stopwords = stopwords.words('spanish')
        
        # Vectorizador TF-IDF mejorado
        self.vectorizer = TfidfVectorizer(
            stop_words=self.spanish_stopwords,
            max_features=5000,
            ngram_range=(1, 3),  # Incluye trigramas para capturar frases más complejas
            min_df=2,            # Ignora términos que aparecen en menos de 2 documentos
            max_df=0.95          # Ignora términos que aparecen en más de 95% de los documentos
        )
        
        # Configurar dispositivo para PyTorch
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"Usando dispositivo: {self.device}")
        
        # Inicializar modelos especializados mejorados
        try:
            # Crear modelos
            self.modelo_contenido = EnhancedContenidoEvaluator(input_dim=5000, hidden_dim=768)
            self.modelo_codigo = EnhancedCodigoEvaluator(input_dim=5000, hidden_dim=768)
            
            # Mover modelos al dispositivo de manera segura
            # Primero asegurarse de que los modelos estén en CPU antes de moverlos
            self.modelo_contenido = self.modelo_contenido.to("cpu")
            self.modelo_codigo = self.modelo_codigo.to("cpu")
            
            # Ahora mover al dispositivo deseado
            self.modelo_contenido = self.modelo_contenido.to(self.device)
            self.modelo_codigo = self.modelo_codigo.to(self.device)
            
            # Optimizadores
            self.optimizer_contenido = optim.Adam(self.modelo_contenido.parameters(), lr=0.001, weight_decay=1e-5)
            self.optimizer_codigo = optim.Adam(self.modelo_codigo.parameters(), lr=0.001, weight_decay=1e-5)
            
            # Función de pérdida
            self.criterion = nn.MSELoss()
            
        except Exception as e:
            logger.error(f"Error al inicializar modelos: {e}")
            self.modelo_contenido = DummyModel()
            self.modelo_codigo = DummyModel()
        
        # Modelo SBERT para análisis semántico profundo (opcional)
        self.use_sbert = use_sbert
        self.sbert_model = None
        if use_sbert:
            try:
                # Intentar importar sentence-transformers
                from sentence_transformers import SentenceTransformer
                
                # Inicializar SBERT de manera segura
                # Primero verificar si CUDA está disponible
                if torch.cuda.is_available():
                    # Configurar para usar CPU primero y luego mover a GPU
                    self.sbert_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device="cpu")
                    # Mover a GPU después de inicializar
                    self.sbert_model.to(self.device)
                else:
                    # Si no hay GPU, usar CPU
                    self.sbert_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device="cpu")
                
                logger.info(f"Modelo SBERT cargado correctamente en dispositivo: {self.sbert_model.device}")
            except ImportError:
                logger.warning("No se pudo importar sentence-transformers. Desactivando SBERT.")
                self.use_sbert = False
            except Exception as e:
                logger.warning(f"No se pudo cargar el modelo SBERT: {e}")
                self.use_sbert = False
        
        # Base de conocimiento ampliada para generación de prácticas
        self.base_conocimiento = [
            "Resolver ecuaciones diferenciales de primer orden utilizando métodos numéricos.",
            "Análisis de datos utilizando técnicas estadísticas descriptivas e inferenciales.",
            "Implementación de algoritmos de ordenamiento y búsqueda para estructuras de datos.",
            "Desarrollo de aplicaciones web con frameworks modernos.",
            "Diseño de bases de datos relacionales y consultas SQL optimizadas.",
            "Análisis de complejidad algorítmica y optimización de código.",
            "Implementación de patrones de diseño en programación orientada a objetos.",
            "Desarrollo de APIs RESTful y servicios web.",
            "Análisis de series temporales y modelos predictivos.",
            "Implementación de sistemas de recomendación basados en filtrado colaborativo.",
            # Nuevos ejemplos para mejorar la base de conocimiento
            "Desarrollo de aplicaciones con arquitectura de microservicios.",
            "Implementación de sistemas de autenticación y autorización seguros.",
            "Análisis de rendimiento y optimización de consultas en bases de datos.",
            "Desarrollo de interfaces de usuario accesibles y responsivas.",
            "Implementación de pruebas unitarias y de integración automatizadas.",
            "Análisis de requisitos y diseño de software orientado a objetos.",
            "Implementación de algoritmos de aprendizaje automático para clasificación y regresión.",
            "Desarrollo de aplicaciones móviles multiplataforma.",
            "Implementación de sistemas de caché y optimización de rendimiento.",
            "Análisis y visualización de datos con bibliotecas especializadas."
        ]

        # Entrenar el vectorizador con la base de conocimiento
        self.tfidf_matrix = self.vectorizer.fit_transform(self.base_conocimiento)
        
        # Cargar plantillas de retroalimentación
        self.cargar_plantillas_retroalimentacion()
        
        # Cargar recursos educativos por estilo de aprendizaje
        self.cargar_recursos_educativos()
        
        # Intentar cargar modelos pre-entrenados
        self.cargar_modelos()
        
        # Diccionario para almacenar métricas de evaluación
        self.metricas_evaluacion = {
            'claridad': self._evaluar_claridad,
            'profundidad': self._evaluar_profundidad,
            'estructura': self._evaluar_estructura,
            'originalidad': self._evaluar_originalidad,
            'relevancia': self._calcular_relevancia
        }
        
        # Inicializar contador de evaluaciones para seguimiento
        self.contador_evaluaciones = 0
        
        # Configuración de la base de datos
        self.db_config = db_config
        self.connection = None
        if db_config:
            try:
                self.connection = mysql.connector.connect(**db_config)
                self.cursor = self.connection.cursor(dictionary=True)
                logger.info("Conexión a la base de datos establecida correctamente")
            except Error as e:
                logger.error(f"Error al conectar a la base de datos: {e}")

    def cargar_plantillas_retroalimentacion(self):
        """Carga plantillas de retroalimentación más detalladas y variadas"""
        self.feedback_templates = {
            'excellent': [
                "Excelente trabajo. Has demostrado un dominio completo del tema, con un análisis profundo y bien estructurado.",
                "Trabajo sobresaliente. Cumples con todos los requisitos y vas más allá, demostrando comprensión avanzada de los conceptos.",
                "Felicitaciones por un trabajo excepcional. Tu análisis demuestra comprensión profunda y capacidad para conectar conceptos complejos.",
                "Trabajo de calidad superior. Muestras dominio del tema y capacidad para aplicar los conceptos en situaciones diversas.",
                "Excelente desempeño. Tu trabajo refleja un nivel de comprensión y análisis que supera las expectativas del curso."
            ],
            'very_good': [
                "Muy buen trabajo. Demuestras una sólida comprensión del tema con un análisis bien desarrollado.",
                "Trabajo de alta calidad. Has abordado todos los aspectos importantes del tema con claridad y precisión.",
                "Muy buen desempeño. Tu trabajo muestra dominio de los conceptos clave y buena capacidad de análisis.",
                "Trabajo muy completo. Has logrado integrar los conceptos de manera coherente y bien fundamentada.",
                "Muy buen análisis. Tu trabajo demuestra comprensión profunda y capacidad para aplicar los conceptos adecuadamente."
            ],
            'good': [
                "Buen trabajo. Cumples con la mayoría de los requisitos y demuestras comprensión del tema.",
                "Trabajo sólido con varios aspectos destacables. Has abordado los puntos principales del tema.",
                "Has demostrado buena comprensión del tema con algunas áreas para mejorar.",
                "Trabajo bien desarrollado. Muestras dominio de los conceptos básicos y cierta capacidad de análisis.",
                "Buen desempeño general. Tu trabajo cumple con los objetivos principales de la actividad."
            ],
            'average': [
                "Trabajo aceptable. Cumples con los requisitos básicos, pero hay espacio para profundizar.",
                "Has demostrado comprensión básica del tema. Tu trabajo cumple con lo mínimo esperado.",
                "El trabajo cumple con los requisitos esenciales, aunque podría beneficiarse de un análisis más profundo.",
                "Trabajo adecuado. Abordas los conceptos fundamentales, pero podrías desarrollarlos con mayor detalle.",
                "Desempeño satisfactorio. Tu trabajo muestra comprensión de los conceptos básicos del tema."
            ],
            'needs_improvement': [
                "El trabajo necesita mejoras significativas. Revisa cuidadosamente los requisitos de la actividad.",
                "Hay áreas importantes que requieren más atención y desarrollo en tu trabajo.",
                "Es necesario profundizar más en el tema y mejorar la estructura de tu trabajo.",
                "Tu trabajo muestra cierta comprensión del tema, pero necesita mayor desarrollo y claridad.",
                "Se requiere un análisis más detallado y mejor fundamentado para alcanzar los objetivos de la actividad."
            ],
            'poor': [
                "El trabajo no cumple con los requisitos mínimos. Es necesario revisar los conceptos fundamentales.",
                "Es necesario revisar completamente el trabajo y asegurarte de abordar los aspectos clave del tema.",
                "Recomiendo volver a estudiar los conceptos básicos del tema y rehacer el trabajo.",
                "Tu trabajo muestra dificultades importantes en la comprensión de los conceptos fundamentales.",
                "Es necesario un replanteamiento completo del trabajo para cumplir con los objetivos de la actividad."
            ],
            'irrelevant': [
                "El trabajo entregado no tiene relación con el tema solicitado. Es fundamental abordar el tema específico de la actividad.",
                "Tu entrega no aborda el tema requerido. Revisa cuidadosamente el título y objetivo de la actividad.",
                "El contenido no corresponde con lo solicitado. Es necesario enfocarse específicamente en el tema de la actividad.",
                "Tu trabajo se desvía completamente del tema solicitado. Revisa las instrucciones y objetivos de la actividad.",
                "La entrega no aborda el tema requerido. Es esencial centrarse en el objetivo específico de la actividad."
            ]
        }
        
        # Plantillas específicas para código
        self.code_feedback_templates = {
            'excellent': [
                "Excelente implementación. Tu código es eficiente, bien estructurado y sigue las mejores prácticas de programación.",
                "Código sobresaliente. Demuestra un dominio completo de los conceptos de programación y una implementación óptima.",
                "Implementación excepcional. Tu código es claro, eficiente y resuelve el problema de manera elegante.",
                "Código de alta calidad. Muestra un excelente manejo de las estructuras de datos y algoritmos apropiados.",
                "Implementación superior. Tu código es robusto, eficiente y fácil de mantener."
            ],
            'very_good': [
                "Muy buen código. Implementación eficiente y bien estructurada con buena documentación.",
                "Implementación de alta calidad. Tu código resuelve correctamente el problema con un buen diseño.",
                "Muy buen trabajo. Tu código es claro, funcional y sigue buenas prácticas de programación.",
                "Código bien implementado. Muestra buen dominio de los conceptos y técnicas de programación.",
                "Implementación sólida. Tu código es eficiente y está bien organizado."
            ],
            'good': [
                "Buen código. Funciona correctamente y tiene una estructura adecuada.",
                "Implementación correcta. Tu código resuelve el problema aunque podría optimizarse en algunos aspectos.",
                "Buen trabajo. Tu código funciona según lo esperado con algunos aspectos a mejorar.",
                "Código funcional. Implementa la solución requerida con una estructura aceptable.",
                "Implementación adecuada. Tu código cumple con los requisitos básicos del problema."
            ],
            'average': [
                "Código aceptable. Funciona pero podría mejorar en eficiencia y estructura.",
                "Implementación básica. Tu código resuelve el problema pero necesita optimización.",
                "Código funcional con limitaciones. Cumple con lo mínimo pero requiere mejoras importantes.",
                "Implementación sencilla. Resuelve el problema de forma básica sin optimizaciones.",
                "Código adecuado. Funciona para casos simples pero podría fallar en escenarios complejos."
            ],
            'needs_improvement': [
                "El código necesita mejoras significativas. Revisa la lógica y estructura de tu implementación.",
                "Hay problemas importantes en tu código. Es necesario corregir errores y mejorar la eficiencia.",
                "Tu implementación requiere revisión. El código tiene errores o no sigue buenas prácticas.",
                "Es necesario mejorar la calidad del código. Revisa la lógica, estructura y documentación.",
                "Tu código necesita trabajo adicional. Hay problemas de funcionalidad y diseño que deben corregirse."
            ],
            'poor': [
                "El código no cumple con los requisitos mínimos. Es necesario replantearlo completamente.",
                "Implementación incorrecta. Tu código tiene errores graves que impiden su funcionamiento.",
                "Es necesario revisar los conceptos fundamentales de programación y rehacer el código.",
                "Tu implementación muestra dificultades importantes en la comprensión de los conceptos básicos.",
                "El código no funciona correctamente. Es necesario un replanteamiento completo de la solución."
            ]
        }
        
        # Plantillas específicas para diferentes tipos de errores
        self.error_templates = {
            'conceptual': [
                "Hay un error conceptual importante en tu explicación de {concepto}. {explicacion_correcta}",
                "Tu comprensión de {concepto} parece incompleta. {explicacion_correcta}",
                "Existe una confusión conceptual en tu análisis de {concepto}. {explicacion_correcta}"
            ],
            'metodologico': [
                "El enfoque metodológico utilizado no es el más adecuado para este problema. {sugerencia}",
                "Hay un error en la metodología aplicada para resolver {problema}. {correccion}",
                "La secuencia de pasos que has seguido para {tarea} no es óptima. {alternativa}"
            ],
            'argumentativo': [
                "Tu argumento sobre {tema} carece de evidencia suficiente. {sugerencia}",
                "La conclusión sobre {tema} no se deriva lógicamente de las premisas presentadas. {correccion}",
                "Hay una falacia en tu razonamiento sobre {tema}. {explicacion}"
            ],
            'estructural': [
                "La estructura de tu trabajo dificulta la comprensión del contenido. {sugerencia}",
                "La organización de las ideas no sigue una secuencia lógica. {recomendacion}",
                "Falta cohesión entre las diferentes secciones de tu trabajo. {consejo}"
            ],
            'tecnico': [
                "Hay un error técnico en tu implementación de {tecnica}. {solucion}",
                "La sintaxis utilizada en {seccion} no es correcta. {correccion}",
                "Existe un problema en la implementación de {algoritmo}. {alternativa}"
            ],
        }
        
        # Plantillas para errores específicos de código
        self.code_error_templates = {
            'sintaxis': [
                "Hay un error de sintaxis en la línea {linea}. {correccion}",
                "La sintaxis utilizada en {seccion} no es correcta. {sugerencia}",
                "Existe un error de sintaxis que impide la ejecución del código. {solucion}"
            ],
            'logica': [
                "Hay un error lógico en tu implementación de {algoritmo}. {explicacion}",
                "La lógica utilizada en {funcion} no produce el resultado esperado. {correccion}",
                "Existe un problema lógico que causa un comportamiento incorrecto. {solucion}"
            ],
            'eficiencia': [
                "Tu implementación de {algoritmo} podría ser más eficiente. {sugerencia}",
                "La complejidad temporal de tu solución es subóptima. {alternativa}",
                "Existe una forma más eficiente de implementar {funcionalidad}. {mejora}"
            ],
            'estilo': [
                "El estilo de codificación no sigue las convenciones estándar. {sugerencia}",
                "La estructura y organización del código podría mejorar. {recomendacion}",
                "El código carece de comentarios adecuados y documentación. {consejo}"
            ],
            'seguridad': [
                "Hay un problema de seguridad en tu implementación de {funcionalidad}. {riesgo}",
                "Tu código es vulnerable a {tipo_ataque}. {solucion}",
                "Es necesario implementar validaciones para prevenir {vulnerabilidad}. {mejora}"
            ]
        }
        
        # Plantillas para aspectos positivos específicos
        self.strength_templates = {
            'analisis': [
                "Tu análisis de {tema} es particularmente sólido y bien fundamentado.",
                "Demuestras excelente capacidad analítica al abordar {tema}.",
                "La profundidad de tu análisis sobre {tema} es destacable."
            ],
            'sintesis': [
                "Tu capacidad para sintetizar información compleja sobre {tema} es notable.",
                "Has logrado condensar efectivamente los aspectos clave de {tema}.",
                "Tu síntesis de {tema} demuestra comprensión profunda del material."
            ],
            'aplicacion': [
                "La aplicación práctica de los conceptos teóricos es un punto fuerte de tu trabajo.",
                "Demuestras habilidad para aplicar {concepto} en contextos reales.",
                "Tu capacidad para llevar la teoría a la práctica en {tema} es destacable."
            ],
            'creatividad': [
                "El enfoque creativo que has dado a {tema} enriquece significativamente tu trabajo.",
                "Tu perspectiva original sobre {tema} aporta valor adicional al análisis.",
                "La creatividad demostrada en tu abordaje de {tema} es digna de mención."
            ],
            'investigacion': [
                "La calidad de tu investigación sobre {tema} es evidente en todo el trabajo.",
                "Has realizado una investigación exhaustiva que fortalece tus argumentos sobre {tema}.",
                "El respaldo bibliográfico de tu trabajo sobre {tema} es excelente."
            ]
        }
        
        # Plantillas para aspectos positivos específicos de código
        self.code_strength_templates = {
            'algoritmo': [
                "Tu implementación del algoritmo {nombre} es particularmente eficiente.",
                "Demuestras excelente comprensión de los algoritmos utilizados.",
                "La selección y aplicación de algoritmos es un punto fuerte de tu código."
            ],
            'estructura': [
                "La estructura y organización de tu código es clara y facilita su comprensión.",
                "Has logrado una excelente modularización y separación de responsabilidades.",
                "La arquitectura de tu solución demuestra un buen diseño de software."
            ],
            'documentacion': [
                "La documentación de tu código es completa y facilita su comprensión.",
                "Los comentarios son claros, precisos y ayudan a entender la lógica implementada.",
                "La documentación de las funciones y clases es detallada y útil."
            ],
            'manejo_errores': [
                "El manejo de errores y excepciones en tu código es robusto y completo.",
                "Has implementado validaciones adecuadas para prevenir comportamientos inesperados.",
                "Tu código maneja correctamente los casos límite y situaciones excepcionales."
            ],
            'optimizacion': [
                "La optimización de recursos (memoria, tiempo) en tu código es destacable.",
                "Has aplicado técnicas efectivas para mejorar el rendimiento de tu solución.",
                "Tu código muestra atención a la eficiencia y optimización."
            ]
        }

    def cargar_recursos_educativos(self):
        """Carga recursos educativos categorizados por estilo de aprendizaje"""
        self.recursos_educativos = {
            'visual': {
                'programacion': [
                    {"titulo": "Mapas conceptuales de estructuras de datos", "url": "https://www.mindmeister.com/es/map/2010460525"},
                    {"titulo": "Visualización de algoritmos", "url": "https://visualgo.net/en"},
                    {"titulo": "Diagramas de flujo interactivos", "url": "https://app.diagrams.net/"},
                    {"titulo": "Videos sobre patrones de diseño", "url": "https://www.youtube.com/playlist?list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc"},
                    {"titulo": "Infografías sobre arquitectura de software", "url": "https://www.pinterest.com/search/pins/?q=software%20architecture%20infographic"}
                ],
                'matematicas': [
                    {"titulo": "Visualizaciones de conceptos matemáticos", "url": "https://www.geogebra.org/"},
                    {"titulo": "Mapas mentales de cálculo", "url": "https://www.mindmeister.com/es/map/2010460525"},
                    {"titulo": "Videos de explicaciones visuales", "url": "https://www.3blue1brown.com/"},
                    {"titulo": "Gráficos interactivos de funciones", "url": "https://www.desmos.com/calculator"},
                    {"titulo": "Infografías de teoremas clave", "url": "https://www.mathsisfun.com/"}
                ],
                'ciencias': [
                    {"titulo": "Simulaciones de física", "url": "https://phet.colorado.edu/es/simulations/category/physics"},
                    {"titulo": "Animaciones de biología celular", "url": "https://learn.genetics.utah.edu/"},
                    {"titulo": "Mapas conceptuales de ecología", "url": "https://www.mindmeister.com/es/map/2010460525"},
                    {"titulo": "Videos de experimentos científicos", "url": "https://www.youtube.com/c/Veritasium"}
                ]
            },
            'auditivo': {
                'programacion': [
                    {"titulo": "Podcast sobre desarrollo de software", "url": "https://www.codingblocks.net/"},
                    {"titulo": "Audiolibros de patrones de diseño", "url": "https://www.audible.com/pd/Design-Patterns-Audiobook/B07GBLFC2Y"},
                    {"titulo": "Conferencias grabadas sobre programación", "url": "https://www.youtube.com/c/GOTO-"},
                    {"titulo": "Entrevistas con desarrolladores", "url": "https://www.se-radio.net/"},
                    {"titulo": "Discusiones sobre arquitectura de software", "url": "https://www.youtube.com/c/InfoQ"}
                ],
                'matematicas': [
                    {"titulo": "Podcast de matemáticas", "url": "https://www.bbc.co.uk/programmes/p01gyd7j/episodes/downloads"},
                    {"titulo": "Explicaciones verbales de conceptos", "url": "https://www.khanacademy.org/math"},
                    {"titulo": "Audiolibros de historia matemática", "url": "https://www.audible.com/pd/Infinite-Powers-Audiobook/1980036322"},
                    {"titulo": "Conferencias grabadas de matemáticos", "url": "https://www.youtube.com/c/numberphile"},
                    {"titulo": "Discusiones sobre teoremas y pruebas", "url": "https://www.youtube.com/c/MathologerChannel"}
                ],
                'ciencias': [
                    {"titulo": "Podcast de ciencia", "url": "https://www.scientificamerican.com/podcast/science-talk/"},
                    {"titulo": "Audiolibros de divulgación científica", "url": "https://www.audible.com/pd/A-Short-History-of-Nearly-Everything-Audiobook/B002V0KFPW"},
                    {"titulo": "Conferencias grabadas de científicos", "url": "https://www.ted.com/topics/science"},
                    {"titulo": "Entrevistas con expertos en ciencia", "url": "https://www.npr.org/podcasts/583350334/science-friday"},
                    {"titulo": "Discusiones sobre avances científicos", "url": "https://www.bbc.co.uk/programmes/b036f7w2/episodes/downloads"}
                ]
            },
            'kinestesico': {
                'programacion': [
                    {"titulo": "Ejercicios prácticos de programación", "url": "https://www.hackerrank.com/"},
                    {"titulo": "Proyectos guiados paso a paso", "url": "https://www.freecodecamp.org/"},
                    {"titulo": "Simuladores de código interactivos", "url": "https://codesandbox.io/"},
                    {"titulo": "Talleres prácticos de desarrollo", "url": "https://www.codecademy.com/"},
                    {"titulo": "Desafíos de programación competitiva", "url": "https://leetcode.com/"}
                ],
                'matematicas': [
                    {"titulo": "Ejercicios interactivos de matemáticas", "url": "https://www.khanacademy.org/math/exercises"},
                    {"titulo": "Manipulativos virtuales", "url": "https://www.mathplayground.com/"},
                    {"titulo": "Proyectos prácticos de matemáticas aplicadas", "url": "https://www.mathsisfun.com/games/"},
                    {"titulo": "Simulaciones interactivas", "url": "https://www.geogebra.org/"},
                    {"titulo": "Juegos matemáticos", "url": "https://www.coolmathgames.com/"}
                ],
                'ciencias': [
                    {"titulo": "Experimentos caseros guiados", "url": "https://www.sciencebuddies.org/"},
                    {"titulo": "Laboratorios virtuales", "url": "https://phet.colorado.edu/es/simulations/category/chemistry"},
                    {"titulo": "Proyectos de ciencia aplicada", "url": "https://www.instructables.com/Science-Projects/"},
                    {"titulo": "Actividades prácticas de campo", "url": "https://www.nationalgeographic.org/education/"},
                    {"titulo": "Simulaciones interactivas de fenómenos", "url": "https://www.exploratorium.edu/explore"}
                ]
            },
            'lectura_escritura': {
                'programacion': [
                    {"titulo": "Libros de referencia de programación", "url": "https://www.oreilly.com/"},
                    {"titulo": "Documentación técnica detallada", "url": "https://devdocs.io/"},
                    {"titulo": "Artículos sobre buenas prácticas", "url": "https://martinfowler.com/"},
                    {"titulo": "Tutoriales escritos paso a paso", "url": "https://www.w3schools.com/"},
                    {"titulo": "Blogs de desarrollo de software", "url": "https://dev.to/"}
                ],
                'matematicas': [
                    {"titulo": "Libros de texto de matemáticas", "url": "https://openstax.org/subjects/math"},
                    {"titulo": "Artículos académicos", "url": "https://arxiv.org/archive/math"},
                    {"titulo": "Guías de estudio detalladas", "url": "https://www.mathsisfun.com/"},
                    {"titulo": "Problemas resueltos con explicaciones", "url": "https://www.purplemath.com/"},
                    {"titulo": "Notas de clase estructuradas", "url": "https://ocw.mit.edu/courses/mathematics/"}
                ],
                'ciencias': [
                    {"titulo": "Libros de texto de ciencias", "url": "https://openstax.org/subjects/science"},
                    {"titulo": "Artículos científicos accesibles", "url": "https://www.sciencedaily.com/"},
                    {"titulo": "Guías de laboratorio detalladas", "url": "https://www.flinnsci.com/"},
                    {"titulo": "Enciclopedias científicas", "url": "https://www.britannica.com/science"},
                    {"titulo": "Revistas de divulgación científica", "url": "https://www.scientificamerican.com/"}
                ]
            }
        }

    def detectar_tipo_contenido(self, contenido: str) -> str:
        """
        Detecta automáticamente el tipo de contenido para aplicar el evaluador adecuado.
        
        Args:
            contenido: Texto a analizar
            
        Returns:
            Tipo de contenido: 'codigo', 'texto', 'matematico', etc.
        """
        # Indicadores de código
        indicadores_codigo = [
            'def ', 'class ', 'function', 'import ', 'from ', 'return ', 'if ', 'else:', 'for ', 'while ',
            '{', '}', ';', 'public ', 'private ', 'protected ', 'static ', 'void ', 'int ', 'float ',
            'string ', 'bool ', 'var ', 'const ', 'let ', 'console.log', 'print(', 'System.out', 'cout <<',
            'SELECT ', 'FROM ', 'WHERE ', 'INSERT INTO', 'UPDATE ', 'DELETE FROM', 'CREATE TABLE'
        ]
        
        # Indicadores de contenido matemático
        indicadores_matematico = [
            '\\begin{equation}', '\\end{equation}', '\\frac', '\\sum', '\\int', '\\prod', '\\lim',
            '\\alpha', '\\beta', '\\gamma', '\\delta', '\\theta', '\\lambda', '\\pi', '\\sigma',
            '\\sqrt', '\\partial', '\\nabla', '\\infty', '\\approx', '\\neq', '\\geq', '\\leq',
            '\\in', '\\subset', '\\cup', '\\cap', '\\emptyset', '\\mathbb', '\\mathcal', '\\mathrm'
        ]
        
        # Contar indicadores
        contador_codigo = sum(1 for ind in indicadores_codigo if ind in contenido)
        contador_matematico = sum(1 for ind in indicadores_matematico if ind in contenido)
        
        # Calcular porcentajes (normalizado por la cantidad de indicadores)
        porcentaje_codigo = contador_codigo / len(indicadores_codigo)
        porcentaje_matematico = contador_matematico / len(indicadores_matematico)
        
        # Determinar tipo de contenido
        if porcentaje_codigo > 0.1:  # Si más del 10% de los indicadores de código están presentes
            return 'codigo'
        elif porcentaje_matematico > 0.1:  # Si más del 10% de los indicadores matemáticos están presentes
            return 'matematico'
        else:
            return 'texto'

    def analizar_contenido(self, contenido_archivo, titulo_actividad="", objetivo_actividad="", estilo_aprendizaje=None):
        """
        Analiza el contenido del archivo y devuelve una calificación y comentarios detallados.
        Incorpora análisis semántico profundo, evaluación multidimensional y personalización por estilo de aprendizaje.
        
        Args:
            contenido_archivo: Texto del contenido entregado
            titulo_actividad: Título de la actividad
            objetivo_actividad: Objetivo de la actividad
            estilo_aprendizaje: Estilo(s) de aprendizaje del estudiante (separados por comas)
            
        Returns:
            Diccionario con calificación, comentarios, sugerencias, relevancia y recursos recomendados
        """
        # Incrementar contador de evaluaciones
        self.contador_evaluaciones += 1
        logger.info(f"Iniciando análisis de contenido #{self.contador_evaluaciones}")
        
        # Validar que el contenido no esté vacío
        if not contenido_archivo or not contenido_archivo.strip():
            logger.warning("Contenido vacío detectado")
            return {
                "calificacion": 0.0,
                "comentarios": "El archivo está vacío o no contiene texto válido.",
                "sugerencias": "Es necesario entregar un trabajo con contenido para poder evaluarlo.",
                "relevancia": 0.0,
                "recursos_recomendados": []
            }
        
        # Detectar tipo de contenido
        tipo_contenido = self.detectar_tipo_contenido(contenido_archivo)
        logger.info(f"Tipo de contenido detectado: {tipo_contenido}")
        
        # Preprocesar el contenido
        contenido_procesado = self._preprocess_text(contenido_archivo)
        logger.info(f"Contenido preprocesado: {len(contenido_procesado)} caracteres")
        
        # Análisis de relevancia
        relevancia = self._calcular_relevancia(contenido_procesado, titulo_actividad, objetivo_actividad)
        logger.info(f"Relevancia calculada: {relevancia:.4f}")
        
        # Si la relevancia es extremadamente baja, asignar calificación cero
        if relevancia < 0.2:
            logger.warning(f"Contenido irrelevante detectado (relevancia: {relevancia:.4f})")
            return self._generar_respuesta_irrelevante(estilo_aprendizaje, titulo_actividad, objetivo_actividad)
        
        # Análisis multidimensional según tipo de contenido
        if tipo_contenido == 'codigo':
            metricas = self._analizar_metricas_codigo(contenido_procesado, titulo_actividad, objetivo_actividad)
        else:
            metricas = self._analizar_metricas(contenido_procesado, titulo_actividad, objetivo_actividad)
        
        logger.info(f"Métricas calculadas: {metricas}")
        
        # Vectorizar el contenido para el modelo de evaluación
        try:
            contenido_vectorizado = self.vectorizer.transform([contenido_procesado]).toarray()[0]
            
            # Asegurar dimensiones consistentes
            if len(contenido_vectorizado) < 5000:
                contenido_vectorizado = np.pad(contenido_vectorizado, (0, 5000 - len(contenido_vectorizado)), 'constant')
            elif len(contenido_vectorizado) > 5000:
                contenido_vectorizado = contenido_vectorizado[:5000]
                
            # Convertir a tensor
            contenido_tensor = torch.tensor(contenido_vectorizado, dtype=torch.float32).unsqueeze(0).to(self.device)
            
            # Generar predicción base según tipo de contenido
            if tipo_contenido == 'codigo':
                self.modelo_codigo.eval()
                with torch.no_grad():
                    outputs = self.modelo_codigo(contenido_tensor)
                    pred_base = outputs['global'].cpu().numpy()[0][0]
                    logger.info(f"Predicción base del modelo de código: {pred_base}")
            else:
                self.modelo_contenido.eval()
                with torch.no_grad():
                    outputs = self.modelo_contenido(contenido_tensor)
                    pred_base = outputs['global'].cpu().numpy()[0][0]
                    logger.info(f"Predicción base del modelo de contenido: {pred_base}")
        except Exception as e:
            logger.error(f"Error en la vectorización o predicción: {e}")
            # Usar un enfoque alternativo basado en métricas si falla la predicción
            pred_base = self._calcular_calificacion_alternativa(metricas)
            logger.info(f"Usando calificación alternativa: {pred_base}")
        
        # Ajustar calificación según métricas y relevancia
        if tipo_contenido == 'codigo':
            calificacion_ajustada = self._ajustar_calificacion_codigo(
                pred_base, 
                relevancia, 
                metricas['funcionalidad'], 
                metricas['eficiencia'], 
                metricas['estilo'],
                metricas['documentacion']
            )
        else:
            calificacion_ajustada = self._ajustar_calificacion(
                pred_base, 
                relevancia, 
                metricas['claridad'], 
                metricas['profundidad'], 
                metricas['estructura']
            )
        
        # Limitar a rango 0-10
        calificacion_final = min(10.0, max(0.0, calificacion_ajustada))
        logger.info(f"Calificación final: {calificacion_final:.2f}")
        
        # Identificar fortalezas y debilidades según tipo de contenido
        if tipo_contenido == 'codigo':
            fortalezas, debilidades = self._identificar_fortalezas_debilidades_codigo(
                contenido_procesado, 
                metricas, 
                calificacion_final
            )
        else:
            fortalezas, debilidades = self._identificar_fortalezas_debilidades(
                contenido_procesado, 
                metricas, 
                calificacion_final
            )
        
        logger.info(f"Fortalezas identificadas: {len(fortalezas)}")
        logger.info(f"Debilidades identificadas: {len(debilidades)}")
        
        # Generar comentarios detallados según tipo de contenido
        if tipo_contenido == 'codigo':
            comentarios = self._generar_comentarios_detallados_codigo(
                calificacion_final, 
                contenido_procesado, 
                titulo_actividad, 
                objetivo_actividad, 
                fortalezas, 
                debilidades,
                estilo_aprendizaje
            )
        else:
            comentarios = self._generar_comentarios_detallados(
                calificacion_final, 
                contenido_procesado, 
                titulo_actividad, 
                objetivo_actividad, 
                fortalezas, 
                debilidades,
                estilo_aprendizaje
            )
        
        # Generar sugerencias de mejora según tipo de contenido
        if tipo_contenido == 'codigo':
            sugerencias = self._generar_sugerencias_mejora_codigo(
                calificacion_final, 
                contenido_procesado, 
                titulo_actividad, 
                objetivo_actividad, 
                debilidades,
                estilo_aprendizaje
            )
        else:
            sugerencias = self._generar_sugerencias_mejora(
                calificacion_final, 
                contenido_procesado, 
                titulo_actividad, 
                objetivo_actividad, 
                debilidades,
                estilo_aprendizaje
            )
        
        # Recomendar recursos educativos según estilo de aprendizaje
        recursos_recomendados = self._recomendar_recursos(
            estilo_aprendizaje, 
            titulo_actividad, 
            objetivo_actividad, 
            calificacion_final
        )
        
        # Construir respuesta completa
        respuesta = {
            "calificacion": float(round(calificacion_final, 1)),  # Asegurar que sea float
            "comentarios": comentarios,
            "sugerencias": sugerencias,
            "relevancia": float(round(relevancia * 100, 1)),  # Como porcentaje
            "tipo_contenido": tipo_contenido,
            "metricas": self._formatear_metricas(metricas, tipo_contenido),
            "fortalezas": fortalezas[:3],  # Limitar a 3 fortalezas principales
            "debilidades": debilidades[:3],  # Limitar a 3 debilidades principales
            "recursos_recomendados": recursos_recomendados
        }
        
        logger.info(f"Análisis de contenido #{self.contador_evaluaciones} completado")
        return respuesta

    # Implementar los métodos auxiliares necesarios
    def _preprocess_text(self, text):
        """Preprocesa el texto para análisis."""
        if not text:
            return ""
            
        # Convertir a minúsculas
        text = text.lower()
        
        # Eliminar caracteres especiales pero mantener puntuación importante
        text = re.sub(r'[^\w\s.,;:¿?¡!()"-]', '', text)
        
        # Eliminar espacios extra
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    def _calcular_relevancia(self, contenido, titulo, objetivo):
        """Calcula la relevancia semántica entre el contenido y los requisitos."""
        if not titulo and not objetivo:
            return 1.0  # Si no hay título/objetivo, asumir relevancia completa
            
        # Combinar título y objetivo
        requisitos = f"{titulo} {objetivo}"
        
        # Usar modelo SBERT si está disponible
        if self.use_sbert and self.sbert_model is not None:
            try:
                # Obtener embeddings
                embedding_requisitos = self.sbert_model.encode([requisitos])[0]
                embedding_contenido = self.sbert_model.encode([contenido[:512]])[0]
                
                # Calcular similitud del coseno
                similarity = cosine_similarity(
                    [embedding_requisitos], 
                    [embedding_contenido]
                )[0][0]
                
                return max(0.0, min(1.0, similarity))  # Asegurar rango 0-1
            except Exception as e:
                logger.warning(f"Error al calcular relevancia con SBERT: {e}")
                # Fallback a método TF-IDF
        
        # Método TF-IDF (fallback)
        try:
            # Vectorizar ambos textos
            vec_requisitos = self.vectorizer.transform([requisitos])
            vec_contenido = self.vectorizer.transform([contenido])
            
            # Calcular similitud del coseno
            similarity = cosine_similarity(vec_requisitos, vec_contenido)[0][0]
            
            return max(0.0, min(1.0, similarity))  # Asegurar rango 0-1
        except Exception as e:
            logger.error(f"Error al calcular relevancia con TF-IDF: {e}")
            
            # Método de respaldo simple basado en palabras clave
            palabras_clave = set(requisitos.split())
            palabras_contenido = set(contenido.split())
            palabras_comunes = palabras_clave.intersection(palabras_contenido)
            
            if len(palabras_clave) > 0:
                return len(palabras_comunes) / len(palabras_clave)
            return 0.5  # Valor por defecto

    def guardar_modelos(self, ruta_base='modelos'):
        """Guarda los modelos y vectorizador en disco."""
        try:
            # Crear directorio si no existe
            os.makedirs(ruta_base, exist_ok=True)
            
            # Guardar modelos
            torch.save(self.modelo_contenido.state_dict(), os.path.join(ruta_base, 'modelo_contenido_enhanced.pt'))
            torch.save(self.modelo_codigo.state_dict(), os.path.join(ruta_base, 'modelo_codigo_enhanced.pt'))
            
            # Guardar vectorizador
            with open(os.path.join(ruta_base, 'vectorizer_enhanced.pkl'), 'wb') as f:
                pickle.dump(self.vectorizer, f)
                
            logger.info(f"Modelos guardados en {ruta_base}")
            return True
        except Exception as e:
            logger.error(f"Error al guardar modelos: {e}")
            return False

    def cargar_modelos(self, ruta_base='modelos'):
        """Carga los modelos y vectorizador desde disco."""
        try:
            # Verificar si los archivos existen
            ruta_contenido = os.path.join(ruta_base, 'modelo_contenido_enhanced.pt')
            ruta_codigo = os.path.join(ruta_base, 'modelo_codigo_enhanced.pt')
            ruta_vectorizer = os.path.join(ruta_base, 'vectorizer_enhanced.pkl')
            
            if not os.path.exists(ruta_contenido) or not os.path.exists(ruta_codigo) or not os.path.exists(ruta_vectorizer):
                # Intentar cargar modelos antiguos
                ruta_contenido_old = os.path.join(ruta_base, 'modelo_contenido.pt')
                ruta_codigo_old = os.path.join(ruta_base, 'modelo_codigo.pt')
                ruta_vectorizer_old = os.path.join(ruta_base, 'vectorizer.pkl')
                
                if os.path.exists(ruta_contenido_old) and os.path.exists(ruta_codigo_old) and os.path.exists(ruta_vectorizer_old):
                    logger.info("Cargando modelos antiguos y actualizándolos...")
                    # Cargar vectorizador antiguo
                    with open(ruta_vectorizer_old, 'rb') as f:
                        self.vectorizer = pickle.load(f)
                    
                    # Guardar modelos nuevos (inicializados aleatoriamente)
                    self.guardar_modelos(ruta_base)
                    return True
                else:
                    logger.warning("Archivos de modelo no encontrados. Se usarán modelos nuevos.")
                    return False
                
            # Cargar modelos
            self.modelo_contenido.load_state_dict(torch.load(ruta_contenido, map_location=self.device))
            self.modelo_contenido.eval()
            
            self.modelo_codigo.load_state_dict(torch.load(ruta_codigo, map_location=self.device))
            self.modelo_codigo.eval()
            
            # Cargar vectorizador
            with open(ruta_vectorizer, 'rb') as f:
                self.vectorizer = pickle.load(f)
                
            logger.info(f"Modelos cargados desde {ruta_base}")
            return True
        except Exception as e:
            logger.error(f"Error al cargar modelos: {e}")
            return False

    def generar_practica(self, titulo, objetivo):
        """
        Genera una práctica completa y detallada basada en el título y objetivo.
        """
        # Combinar título y objetivo
        prompt = f"{titulo}. {objetivo}"
        
        # Encontrar prácticas similares en la base de conocimiento
        prompt_vec = self.vectorizer.transform([prompt])
        similarities = cosine_similarity(prompt_vec, self.tfidf_matrix)
        
        # Obtener los 3 ejemplos más similares
        top_indices = similarities[0].argsort()[-3:][::-1]
        practicas_similares = [self.base_conocimiento[i] for i in top_indices]
        
        # Determinar la categoría temática
        categoria = self._determinar_categoria_tematica(titulo, objetivo)
        
        # Generar descripción combinando elementos de prácticas similares
        descripcion = f"Esta práctica se enfoca en {titulo.lower()}. "
        descripcion += f"{practicas_similares[0]} "
        if len(practicas_similares) > 1:
            descripcion += f"Además, aborda aspectos relacionados con {practicas_similares[1].lower()}."
        
        # Generar instrucciones específicas según la categoría
        instrucciones = [
            f"Lee detenidamente el objetivo: {objetivo}",
            "Investiga los conceptos teóricos relacionados con el tema"
        ]
        
        if categoria == 'programacion':
            instrucciones.extend([
                "Diseña una solución que cumpla con los requisitos especificados",
                "Implementa tu solución utilizando el lenguaje de programación adecuado",
                "Documenta tu código con comentarios explicativos",
                "Realiza pruebas para verificar el correcto funcionamiento",
                "Analiza la complejidad y eficiencia de tu solución"
            ])
        elif categoria == 'matematicas':
            instrucciones.extend([
                "Identifica los conceptos matemáticos relevantes para el problema",
                "Desarrolla paso a paso la solución, justificando cada etapa",
                "Incluye demostraciones cuando sea necesario",
                "Verifica tus resultados con ejemplos concretos",
                "Analiza las implicaciones y aplicaciones de tu solución"
            ])
        elif categoria == 'ciencias':
            instrucciones.extend([
                "Formula una hipótesis basada en el objetivo planteado",
                "Diseña un experimento o metodología para comprobar tu hipótesis",
                "Recopila y analiza datos relevantes",
                "Interpreta los resultados obtenidos",
                "Elabora conclusiones fundamentadas en la evidencia"
            ])
        
        instrucciones.append("Entrega tu trabajo antes de la fecha límite establecida")
        
        # Generar recursos recomendados
        recursos = [
            "Material de clase y apuntes",
            "Biblioteca digital de la universidad"
        ]
        
        if categoria == 'programacion':
            recursos.extend([
                "Documentación oficial del lenguaje de programación",
                "Repositorios de código en GitHub",
                "Foros especializados como Stack Overflow"
            ])
        elif categoria == 'matematicas':
            recursos.extend([
                "Libros de texto recomendados en el curso",
                "Artículos académicos relacionados",
                "Plataformas como Khan Academy o Wolfram Alpha"
            ])
        elif categoria == 'ciencias':
            recursos.extend([
                "Artículos científicos recientes sobre el tema",
                "Bases de datos especializadas",
                "Simuladores y laboratorios virtuales"
            ])
        
        # Generar criterios de evaluación
        criterios_evaluacion = [
            "Comprensión del tema y conceptos clave (30%)",
            "Calidad de la solución o análisis (40%)",
            "Documentación y presentación (20%)",
            "Creatividad e innovación (10%)"
        ]
        
        # Generar objetivos de aprendizaje
        objetivos_aprendizaje = []
        
        if categoria == 'programacion':
            objetivos_aprendizaje = [
                f"Comprender los fundamentos teóricos de {titulo.lower()}",
                "Desarrollar habilidades de resolución de problemas mediante programación",
                "Aplicar buenas prácticas de desarrollo de software",
                "Implementar soluciones eficientes y bien documentadas"
            ]
        elif categoria == 'matematicas':
            objetivos_aprendizaje = [
                f"Dominar los conceptos matemáticos relacionados con {titulo.lower()}",
                "Desarrollar capacidad de razonamiento lógico y abstracto",
                "Aplicar métodos matemáticos para resolver problemas concretos",
                "Comunicar ideas matemáticas con precisión y claridad"
            ]
        elif categoria == 'ciencias':
            objetivos_aprendizaje = [
                f"Comprender los principios científicos de {titulo.lower()}",
                "Desarrollar habilidades de investigación y análisis",
                "Aplicar el método científico en situaciones concretas",
                "Interpretar datos y resultados experimentales"
            ]
        
        # Generar recomendaciones según la categoría
        recomendaciones = ""
        if categoria == 'programacion':
            recomendaciones = (
                "Se recomienda practicar en plataformas como LeetCode y consultar documentación oficial."
            )
        elif categoria == 'matematicas':
            recomendaciones = (
                "Utiliza herramientas como Wolfram Alpha y busca problemas similares en Khan Academy."
            )
        elif categoria == 'ciencias':
            recomendaciones = (
                "Refuerza tus conocimientos con simuladores virtuales y experimentos caseros controlados."
            )
        else:
            recomendaciones = (
                "Consulta con tu profesor o utiliza recursos digitales para profundizar en el tema."
            )
    
        # Construir y retornar la práctica completa
        nueva_practica = {
            "titulo": titulo,
            "objetivo": objetivo,
            "objetivos_aprendizaje": objetivos_aprendizaje,
            "descripcion": descripcion,
            "actividades": instrucciones,  # Reusamos instrucciones como actividades
            "categoria": categoria,
            "instrucciones": instrucciones,
            "recursos": recursos,
            "criterios_evaluacion": criterios_evaluacion,
            "tiempo_estimado": "2-3 horas",
            "nivel_dificultad": "Intermedio",
            "recomendaciones": recomendaciones
        }
    
        return nueva_practica

    def _determinar_categoria_tematica(self, titulo, objetivo):
        """
        Determina la categoría temática del trabajo basándose en el título y objetivo.
        """
        if not titulo and not objetivo:
            return "programacion"  # Categoría por defecto
            
        texto_combinado = f"{titulo} {objetivo}".lower()
        
        # Palabras clave por categoría
        keywords = {
            'programacion': ['programación', 'código', 'algoritmo', 'desarrollo', 'software', 'aplicación', 
                           'web', 'móvil', 'base de datos', 'api', 'interfaz', 'función', 'clase', 
                           'objeto', 'variable', 'python', 'java', 'javascript', 'html', 'css'],
            'matematicas': ['matemáticas', 'cálculo', 'álgebra', 'geometría', 'estadística', 'probabilidad', 
                          'función', 'ecuación', 'teorema', 'demostración', 'conjunto', 'matriz', 
                          'vector', 'integral', 'derivada', 'límite', 'serie', 'convergencia'],
            'ciencias': ['física', 'química', 'biología', 'geología', 'astronomía', 'experimento', 
                       'laboratorio', 'científico', 'teoría', 'hipótesis', 'observación', 'fenómeno', 
                       'reacción', 'molécula', 'célula', 'organismo', 'ecosistema', 'energía']
        }
        
        # Contar coincidencias por categoría
        coincidencias = defaultdict(int)
        for categoria, palabras in keywords.items():
            for palabra in palabras:
                if palabra in texto_combinado:
                    coincidencias[categoria] += 1
        
        # Determinar la categoría con más coincidencias
        if not coincidencias:
            return "programacion"  # Categoría por defecto
            
        return max(coincidencias.items(), key=lambda x: x[1])[0]
    
    def _analizar_metricas(self, contenido, titulo, objetivo):
        """Analiza métricas de calidad para contenido textual."""
        metricas = {}
        
        # Calcular métricas básicas
        metricas['claridad'] = self._evaluar_claridad(contenido)
        metricas['profundidad'] = self._evaluar_profundidad(contenido)
        metricas['estructura'] = self._evaluar_estructura(contenido)
        metricas['originalidad'] = self._evaluar_originalidad(contenido)
        metricas['relevancia'] = self._calcular_relevancia(contenido, titulo, objetivo)
        
        return metricas
    
    def _analizar_metricas_codigo(self, contenido, titulo, objetivo):
        """Analiza métricas de calidad específicas para código."""
        metricas = {}
        
        # Calcular métricas específicas para código
        metricas['funcionalidad'] = self._evaluar_funcionalidad_codigo(contenido)
        metricas['eficiencia'] = self._evaluar_eficiencia_codigo(contenido)
        metricas['estilo'] = self._evaluar_estilo_codigo(contenido)
        metricas['documentacion'] = self._evaluar_documentacion_codigo(contenido)
        metricas['relevancia'] = self._calcular_relevancia(contenido, titulo, objetivo)
        
        return metricas
    
    def _evaluar_claridad(self, texto):
        """Evalúa la claridad del texto."""
        # Métricas simples de claridad
        palabras = texto.split()
        if not palabras:
            return 0.5  # Valor por defecto
            
        # Longitud promedio de palabras (palabras más cortas suelen ser más claras)
        longitud_promedio = sum(len(p) for p in palabras) / len(palabras)
        claridad_longitud = max(0, min(1, 2 - longitud_promedio / 10))
        
        # Variedad de vocabulario (menos variedad suele indicar más claridad)
        vocabulario_unico = len(set(palabras))
        ratio_vocabulario = vocabulario_unico / len(palabras)
        claridad_vocabulario = max(0, min(1, 1.5 - ratio_vocabulario))
        
        # Presencia de conectores lógicos (mejora la claridad)
        conectores = ['porque', 'por lo tanto', 'así', 'entonces', 'además', 'sin embargo', 'aunque', 'pero']
        conectores_presentes = sum(1 for c in conectores if c in texto.lower())
        claridad_conectores = min(1, conectores_presentes / 5)
        
        # Combinar métricas (ponderadas)
        claridad = (0.4 * claridad_longitud + 0.3 * claridad_vocabulario + 0.3 * claridad_conectores)
        
        # Escalar a 0-10
        return claridad * 10
    
    def _evaluar_profundidad(self, texto):
        """Evalúa la profundidad del análisis en el texto."""
        palabras = texto.split()
        if not palabras:
            return 0.5  # Valor por defecto
            
        # Longitud del texto (textos más largos suelen tener más profundidad)
        longitud = len(palabras)
        profundidad_longitud = min(1, longitud / 500)
        
        # Variedad de vocabulario (más variedad suele indicar más profundidad)
        vocabulario_unico = len(set(palabras))
        ratio_vocabulario = vocabulario_unico / len(palabras) if len(palabras) > 0 else 0
        profundidad_vocabulario = min(1, ratio_vocabulario * 3)
        
        # Presencia de términos técnicos o específicos
        terminos_tecnicos = ['análisis', 'metodología', 'implementación', 'algoritmo', 'estructura', 
                           'sistema', 'proceso', 'función', 'componente', 'arquitectura', 'paradigma',
                           'teoría', 'concepto', 'principio', 'framework', 'modelo', 'patrón']
        terminos_presentes = sum(1 for t in terminos_tecnicos if t in texto.lower())
        profundidad_terminos = min(1, terminos_presentes / 10)
        
        # Combinar métricas (ponderadas)
        profundidad = (0.3 * profundidad_longitud + 0.4 * profundidad_vocabulario + 0.3 * profundidad_terminos)
        
        # Escalar a 0-10
        return profundidad * 10
    
    def _evaluar_estructura(self, texto):
        """Evalúa la estructura y organización del texto."""
        # Dividir en párrafos
        parrafos = [p for p in texto.split('\n') if p.strip()]
        if not parrafos:
            return 0.5  # Valor por defecto
            
        # Número de párrafos (más párrafos suelen indicar mejor estructura)
        num_parrafos = len(parrafos)
        estructura_parrafos = min(1, num_parrafos / 10)
        
        # Longitud promedio de párrafos (párrafos muy largos o muy cortos penalizan)
        longitud_promedio = sum(len(p.split()) for p in parrafos) / num_parrafos if num_parrafos > 0 else 0
        estructura_longitud = max(0, min(1, 1 - abs(longitud_promedio - 100) / 100))
        
        # Presencia de marcadores de estructura
        marcadores = ['primero', 'segundo', 'finalmente', 'en conclusión', 'por un lado', 'por otro lado',
                     'en resumen', 'en síntesis', 'a continuación', 'anteriormente']
        marcadores_presentes = sum(1 for m in marcadores if m in texto.lower())
        estructura_marcadores = min(1, marcadores_presentes / 5)
        
        # Combinar métricas (ponderadas)
        estructura = (0.3 * estructura_parrafos + 0.3 * estructura_longitud + 0.4 * estructura_marcadores)
        
        # Escalar a 0-10
        return estructura * 10
    
    def _evaluar_originalidad(self, texto):
        """Evalúa la originalidad y creatividad del texto."""
        palabras = texto.split()
        if not palabras:
            return 0.5  # Valor por defecto
            
        # Variedad de vocabulario (más variedad suele indicar más originalidad)
        vocabulario_unico = len(set(palabras))
        ratio_vocabulario = vocabulario_unico / len(palabras) if len(palabras) > 0 else 0
        originalidad_vocabulario = min(1, ratio_vocabulario * 2)
        
        # Presencia de frases poco comunes
        frases_comunes = ['en conclusión', 'en resumen', 'como se mencionó', 'es importante destacar',
                         'cabe señalar', 'es necesario', 'se debe tener en cuenta']
        frases_presentes = sum(1 for f in frases_comunes if f in texto.lower())
        originalidad_frases = max(0, min(1, 1 - frases_presentes / 10))
        
        # Longitud de oraciones (variabilidad en longitud indica más originalidad)
        oraciones = re.split(r'[.!?]+', texto)
        if len(oraciones) > 1:
            longitudes = [len(o.split()) for o in oraciones if o.strip()]
            desviacion = np.std(longitudes) if len(longitudes) > 0 else 0
            originalidad_oraciones = min(1, desviacion / 10)
        else:
            originalidad_oraciones = 0.5
        
        # Combinar métricas (ponderadas)
        originalidad = (0.4 * originalidad_vocabulario + 0.3 * originalidad_frases + 0.3 * originalidad_oraciones)
        
        # Escalar a 0-10
        return originalidad * 10
    
    def _evaluar_funcionalidad_codigo(self, codigo):
        """Evalúa la funcionalidad del código."""
        # Indicadores de buena funcionalidad
        indicadores_positivos = [
            'return', 'print', 'if', 'else', 'for', 'while', 'try', 'except',
            'def ', 'class ', 'import ', 'from '
        ]
        
        # Indicadores de problemas de funcionalidad
        indicadores_negativos = [
            'error', 'exception', 'fail', 'bug', 'issue', 'problem',
            '# TODO', '# FIXME', 'pass  # '
        ]
        
        # Contar indicadores
        positivos = sum(1 for ind in indicadores_positivos if ind in codigo)
        negativos = sum(1 for ind in indicadores_negativos if ind in codigo)
        
        # Calcular puntuación base
        puntuacion_base = min(1, positivos / 10) * 0.8 - min(0.5, negativos / 5) * 0.2
        
        # Verificar estructura básica de funciones/clases
        tiene_funciones = 'def ' in codigo
        tiene_clases = 'class ' in codigo
        tiene_main = 'if __name__' in codigo or 'main()' in codigo
        
        # Bonificación por estructura adecuada
        bonificacion_estructura = 0
        if tiene_funciones:
            bonificacion_estructura += 0.1
        if tiene_clases:
            bonificacion_estructura += 0.1
        if tiene_main:
            bonificacion_estructura += 0.1
        
        # Calcular puntuación final
        funcionalidad = max(0, min(1, puntuacion_base + bonificacion_estructura))
        
        # Escalar a 0-10
        return funcionalidad * 10
    
    def _evaluar_eficiencia_codigo(self, codigo):
        """Evalúa la eficiencia del código."""
        # Indicadores de buena eficiencia
        indicadores_positivos = [
            'O(n)', 'O(1)', 'O(log n)', 'optimiz', 'eficien',
            'dict', 'set', 'list comprehension', 'generator', 'yield',
            'cache', 'memoiz'
        ]
        
        # Indicadores de problemas de eficiencia
        indicadores_negativos = [
            'O(n^2)', 'O(n^3)', 'O(2^n)', 'for i in range', 'for j in range',
            'while True', 'sleep(', 'time.sleep'
        ]
        
        # Contar indicadores
        positivos = sum(1 for ind in indicadores_positivos if ind in codigo)
        negativos = sum(1 for ind in indicadores_negativos if ind in codigo)
        
        # Calcular puntuación base
        puntuacion_base = min(1, positivos / 5) * 0.7 - min(0.5, negativos / 3) * 0.3
        
        # Verificar uso de estructuras de datos eficientes
        usa_dict = 'dict(' in codigo or '{' in codigo
        usa_set = 'set(' in codigo
        usa_list_comp = '[' in codigo and 'for' in codigo and ']' in codigo
        
        # Bonificación por uso de estructuras eficientes
        bonificacion_estructuras = 0
        if usa_dict:
            bonificacion_estructuras += 0.1
        if usa_set:
            bonificacion_estructuras += 0.1
        if usa_list_comp:
            bonificacion_estructuras += 0.1
        
        # Calcular puntuación final
        eficiencia = max(0, min(1, puntuacion_base + bonificacion_estructuras))
        
        # Escalar a 0-10
        return eficiencia * 10
    
    def _evaluar_estilo_codigo(self, codigo):
        """Evalúa el estilo y legibilidad del código."""
        # Indicadores de buen estilo
        indicadores_positivos = [
            '    ', '# ', 'def ', 'class ', 'return', 'self.',
            'if ', 'else:', 'elif ', 'for ', 'while '
        ]
        
        # Indicadores de problemas de estilo
        indicadores_negativos = [
            '\t', '  return', '  if', '  for', '  while',
            'if(', 'for(', 'while(', 'return(', '){', ') {',
            'variable', 'temp', 'tmp', 'foo', 'bar'
        ]
        
        # Contar indicadores
        positivos = sum(1 for ind in indicadores_positivos if ind in codigo)
        negativos = sum(1 for ind in indicadores_negativos if ind in codigo)
        
        # Calcular puntuación base
        puntuacion_base = min(1, positivos / 10) * 0.7 - min(0.5, negativos / 5) * 0.3
        
        # Verificar convenciones de nomenclatura
        lineas = codigo.split('\n')
        nombres_snake_case = sum(1 for l in lineas if re.search(r'[a-z_]+\s*=', l))
        nombres_camel_case = sum(1 for l in lineas if re.search(r'[a-z][a-zA-Z]+\s*=', l))
        
        # Bonificación por nomenclatura consistente
        bonificacion_nomenclatura = 0
        if nombres_snake_case > nombres_camel_case * 2:  # Preferencia por snake_case en Python
            bonificacion_nomenclatura += 0.2
        elif nombres_camel_case > nombres_snake_case * 2:  # O consistencia en camelCase
            bonificacion_nomenclatura += 0.1
        
        # Calcular puntuación final
        estilo = max(0, min(1, puntuacion_base + bonificacion_nomenclatura))
        
        # Escalar a 0-10
        return estilo * 10
    
    def _evaluar_documentacion_codigo(self, codigo):
        """Evalúa la documentación del código."""
        # Contar líneas de código y comentarios
        lineas = codigo.split('\n')
        lineas_codigo = sum(1 for l in lineas if l.strip() and not l.strip().startswith('#'))
        lineas_comentarios = sum(1 for l in lineas if l.strip() and l.strip().startswith('#'))
        
        # Calcular ratio de comentarios
        ratio_comentarios = lineas_comentarios / lineas_codigo if lineas_codigo > 0 else 0
        
        # Verificar presencia de docstrings
        docstrings_triples = codigo.count('"""') // 2  # Cada docstring tiene apertura y cierre
        docstrings_simples = codigo.count("'''") // 2
        total_docstrings = docstrings_triples + docstrings_simples
        
        # Verificar documentación de funciones y clases
        funciones = len(re.findall(r'def\s+\w+\s*\(', codigo))
        clases = len(re.findall(r'class\s+\w+\s*[(:)]', codigo))
        
        # Calcular ratio de documentación de funciones/clases
        elementos_documentables = funciones + clases
        ratio_docstrings = total_docstrings / elementos_documentables if elementos_documentables > 0 else 0
        
        # Calcular puntuación combinada
        documentacion = (ratio_comentarios * 0.4 + ratio_docstrings * 0.6)
        
        # Ajustar para evitar penalizar código simple
        if lineas_codigo < 20 and ratio_comentarios > 0:
            documentacion = max(documentacion, 0.6)
        
        # Escalar a 0-10
        return min(10, documentacion * 10)
    
    def _ajustar_calificacion(self, base, relevancia, claridad, profundidad, estructura):
        """Ajusta la calificación base según métricas adicionales."""
        # Convertir relevancia a escala 0-1
        relevancia_norm = min(1.0, relevancia)
        
        # Normalizar métricas a escala 0-1
        claridad_norm = claridad / 10
        profundidad_norm = profundidad / 10
        estructura_norm = estructura / 10
        
        # Calcular ajuste ponderado
        ajuste = (
            relevancia_norm * 0.4 +
            claridad_norm * 0.2 +
            profundidad_norm * 0.3 +
            estructura_norm * 0.1
        )
        
        # Aplicar ajuste a la base
        calificacion_ajustada = base * 0.6 + ajuste * 4.0  # Ajuste máximo de ±4 puntos
        
        return calificacion_ajustada
    
    def _ajustar_calificacion_codigo(self, base, relevancia, funcionalidad, eficiencia, estilo, documentacion):
        """Ajusta la calificación base para código según métricas específicas."""
        # Convertir relevancia a escala 0-1
        relevancia_norm = min(1.0, relevancia)
        
        # Normalizar métricas a escala 0-1
        funcionalidad_norm = funcionalidad / 10
        eficiencia_norm = eficiencia / 10
        estilo_norm = estilo / 10
        documentacion_norm = documentacion / 10
        
        # Calcular ajuste ponderado
        ajuste = (
            relevancia_norm * 0.3 +
            funcionalidad_norm * 0.3 +
            eficiencia_norm * 0.2 +
            estilo_norm * 0.1 +
            documentacion_norm * 0.1
        )
        
        # Aplicar ajuste a la base
        calificacion_ajustada = base * 0.5 + ajuste * 5.0  # Ajuste máximo de ±5 puntos
        
        return calificacion_ajustada
    
    def _calcular_calificacion_alternativa(self, metricas):
        """Calcula una calificación alternativa basada en métricas cuando falla el modelo."""
        # Extraer métricas relevantes
        if 'funcionalidad' in metricas:  # Es código
            relevancia = metricas.get('relevancia', 0.5)
            funcionalidad = metricas.get('funcionalidad', 5.0)
            eficiencia = metricas.get('eficiencia', 5.0)
            estilo = metricas.get('estilo', 5.0)
            documentacion = metricas.get('documentacion', 5.0)
            
            # Calcular calificación ponderada
            calificacion = (
                relevancia * 10 * 0.3 +
                funcionalidad * 0.3 +
                eficiencia * 0.2 +
                estilo * 0.1 +
                documentacion * 0.1
            )
        else:  # Es texto
            relevancia = metricas.get('relevancia', 0.5)
            claridad = metricas.get('claridad', 5.0)
            profundidad = metricas.get('profundidad', 5.0)
            estructura = metricas.get('estructura', 5.0)
            originalidad = metricas.get('originalidad', 5.0)
            
            # Calcular calificación ponderada
            calificacion = (
                relevancia * 10 * 0.3 +
                claridad * 0.2 +
                profundidad * 0.3 +
                estructura * 0.1 +
                originalidad * 0.1
            )
        
        return calificacion
    
    def _identificar_fortalezas_debilidades(self, contenido, metricas, calificacion):
        """Identifica fortalezas y debilidades en el contenido textual."""
        fortalezas = []
        debilidades = []
        
        # Analizar métricas para identificar fortalezas
        if metricas['claridad'] >= 7.5:
            fortalezas.append("Excelente claridad en la exposición de ideas")
        elif metricas['claridad'] >= 6.0:
            fortalezas.append("Buena claridad en la presentación del contenido")
            
        if metricas['profundidad'] >= 7.5:
            fortalezas.append("Análisis profundo y detallado del tema")
        elif metricas['profundidad'] >= 6.0:
            fortalezas.append("Buen nivel de profundidad en el análisis")
            
        if metricas['estructura'] >= 7.5:
            fortalezas.append("Excelente estructura y organización del contenido")
        elif metricas['estructura'] >= 6.0:
            fortalezas.append("Buena estructura general del trabajo")
            
        if metricas['originalidad'] >= 7.5:
            fortalezas.append("Enfoque original y creativo del tema")
        elif metricas['originalidad'] >= 6.0:
            fortalezas.append("Cierto grado de originalidad en el planteamiento")
            
        if metricas['relevancia'] >= 0.8:
            fortalezas.append("Contenido altamente relevante para el tema solicitado")
        elif metricas['relevancia'] >= 0.6:
            fortalezas.append("Contenido adecuadamente relacionado con el tema")
        
        # Analizar métricas para identificar debilidades
        if metricas['claridad'] < 5.0:
            debilidades.append("Falta claridad en la exposición de ideas")
        elif metricas['claridad'] < 6.0:
            debilidades.append("La claridad en la presentación podría mejorar")
            
        if metricas['profundidad'] < 5.0:
            debilidades.append("Análisis superficial del tema")
        elif metricas['profundidad'] < 6.0:
            debilidades.append("El análisis podría profundizar más en ciertos aspectos")
            
        if metricas['estructura'] < 5.0:
            debilidades.append("Problemas de estructura y organización del contenido")
        elif metricas['estructura'] < 6.0:
            debilidades.append("La estructura del trabajo podría mejorar")
            
        if metricas['originalidad'] < 5.0:
            debilidades.append("Enfoque convencional sin aportes originales")
        elif metricas['originalidad'] < 6.0:
            debilidades.append("Podría incorporar elementos más originales o creativos")
            
        if metricas['relevancia'] < 0.4:
            debilidades.append("El contenido no es suficientemente relevante para el tema solicitado")
        elif metricas['relevancia'] < 0.6:
            debilidades.append("Algunos aspectos del contenido se alejan del tema principal")
        
        # Análisis adicional del contenido
        palabras = contenido.split()
        
        # Verificar longitud
        if len(palabras) < 200:
            debilidades.append("El trabajo es demasiado breve para desarrollar adecuadamente el tema")
        elif len(palabras) > 2000:
            fortalezas.append("Trabajo extenso con desarrollo detallado")
        
        # Verificar variedad de vocabulario
        vocabulario_unico = len(set(palabras))
        ratio_vocabulario = vocabulario_unico / len(palabras) if len(palabras) > 0 else 0
        if ratio_vocabulario > 0.5:
            fortalezas.append("Excelente riqueza de vocabulario")
        elif ratio_vocabulario < 0.3:
            debilidades.append("Vocabulario limitado y repetitivo")
        
        return fortalezas, debilidades
    
    def _identificar_fortalezas_debilidades_codigo(self, codigo, metricas, calificacion):
        """Identifica fortalezas y debilidades específicas en el código."""
        fortalezas = []
        debilidades = []
        
        # Analizar métricas para identificar fortalezas
        if metricas['funcionalidad'] >= 7.5:
            fortalezas.append("Código altamente funcional y bien implementado")
        elif metricas['funcionalidad'] >= 6.0:
            fortalezas.append("Buena implementación funcional del código")
            
        if metricas['eficiencia'] >= 7.5:
            fortalezas.append("Código eficiente con buen uso de recursos")
        elif metricas['eficiencia'] >= 6.0:
            fortalezas.append("Implementación razonablemente eficiente")
            
        if metricas['estilo'] >= 7.5:
            fortalezas.append("Excelente estilo de codificación y legibilidad")
        elif metricas['estilo'] >= 6.0:
            fortalezas.append("Buen estilo de codificación general")
            
        if metricas['documentacion'] >= 7.5:
            fortalezas.append("Código muy bien documentado con comentarios claros")
        elif metricas['documentacion'] >= 6.0:
            fortalezas.append("Documentación adecuada del código")
            
        if metricas['relevancia'] >= 0.8:
            fortalezas.append("Implementación altamente relevante para el problema planteado")
        elif metricas['relevancia'] >= 0.6:
            fortalezas.append("Código adecuadamente relacionado con el problema")
        
        # Analizar métricas para identificar debilidades
        if metricas['funcionalidad'] < 5.0:
            debilidades.append("Problemas significativos de funcionalidad en el código")
        elif metricas['funcionalidad'] < 6.0:
            debilidades.append("La funcionalidad del código podría mejorar")
            
        if metricas['eficiencia'] < 5.0:
            debilidades.append("Código ineficiente con uso subóptimo de recursos")
        elif metricas['eficiencia'] < 6.0:
            debilidades.append("La eficiencia del código podría optimizarse")
            
        if metricas['estilo'] < 5.0:
            debilidades.append("Problemas de estilo y legibilidad en el código")
        elif metricas['estilo'] < 6.0:
            debilidades.append("El estilo de codificación podría mejorar")
            
        if metricas['documentacion'] < 5.0:
            debilidades.append("Falta documentación adecuada en el código")
        elif metricas['documentacion'] < 6.0:
            debilidades.append("La documentación del código podría ser más completa")
            
        if metricas['relevancia'] < 0.4:
            debilidades.append("El código no aborda adecuadamente el problema planteado")
        elif metricas['relevancia'] < 0.6:
            debilidades.append("Algunos aspectos del código se alejan del objetivo principal")
        
        # Análisis adicional del código
        lineas = codigo.split('\n')
        lineas_codigo = [l for l in lineas if l.strip() and not l.strip().startswith('#')]
        
        # Verificar longitud
        if len(lineas_codigo) < 10:
            debilidades.append("El código es demasiado breve para resolver adecuadamente el problema")
        elif len(lineas_codigo) > 200:
            if metricas['eficiencia'] < 6.0:
                debilidades.append("Código extenso que podría simplificarse para mayor eficiencia")
            else:
                fortalezas.append("Implementación completa y detallada")
        
        # Verificar uso de funciones/clases
        if 'def ' in codigo and 'class ' in codigo:
            fortalezas.append("Buen uso de programación orientada a objetos y modularización")
        elif 'def ' in codigo:
            fortalezas.append("Buena modularización del código en funciones")
        elif len(lineas_codigo) > 30 and 'def ' not in codigo:
            debilidades.append("Falta modularización del código en funciones")
        
        return fortalezas, debilidades
    
    def _generar_comentarios_detallados(self, calificacion, contenido, titulo, objetivo, fortalezas, debilidades, estilo_aprendizaje):
        """Genera comentarios detallados para contenido textual."""
        # Determinar categoría de calificación
        if calificacion >= 9.0:
            categoria = 'excellent'
        elif calificacion >= 8.0:
            categoria = 'very_good'
        elif calificacion >= 7.0:
            categoria = 'good'
        elif calificacion >= 5.0:
            categoria = 'average'
        elif calificacion >= 3.0:
            categoria = 'needs_improvement'
        else:
            categoria = 'poor'
        
        # Seleccionar plantilla base según categoría
        import random
        plantilla_base = random.choice(self.feedback_templates[categoria])
        
        # Personalizar comentario según estilo de aprendizaje
        comentario_personalizado = ""
        if estilo_aprendizaje:
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            if 'visual' in estilos:
                comentario_personalizado += "Te recomiendo organizar tus ideas en mapas conceptuales o diagramas para reforzar tu comprensión visual del tema."
            
            if 'auditivo' in estilos:
                comentario_personalizado += " Considera explicar tus ideas en voz alta o discutirlas con otros para reforzar tu comprensión auditiva."
                
            if 'kinestesico' in estilos:
                comentario_personalizado += " Te beneficiaría aplicar estos conceptos en ejercicios prácticos o simulaciones para reforzar tu aprendizaje kinestésico."
                
            if 'lectura_escritura' in estilos:
                comentario_personalizado += " Continúa desarrollando tus ideas por escrito y consultando fuentes bibliográficas para fortalecer tu estilo de aprendizaje."
        
        # Incorporar fortalezas y debilidades
        comentario_fortalezas = ""
        if fortalezas:
            comentario_fortalezas = "\n\nFortalezas destacadas:\n- " + "\n- ".join(fortalezas[:3])
            
        comentario_debilidades = ""
        if debilidades:
            comentario_debilidades = "\n\nAspectos a mejorar:\n- " + "\n- ".join(debilidades[:3])
        
        # Construir comentario completo
        comentario_completo = f"{plantilla_base}\n\n"
        
        if comentario_personalizado:
            comentario_completo += f"Considerando tu estilo de aprendizaje: {comentario_personalizado}\n"
            
        comentario_completo += f"{comentario_fortalezas}{comentario_debilidades}"
        
        return comentario_completo
    
    def _generar_comentarios_detallados_codigo(self, calificacion, codigo, titulo, objetivo, fortalezas, debilidades, estilo_aprendizaje):
        """Genera comentarios detallados específicos para código."""
        # Determinar categoría de calificación
        if calificacion >= 9.0:
            categoria = 'excellent'
        elif calificacion >= 8.0:
            categoria = 'very_good'
        elif calificacion >= 7.0:
            categoria = 'good'
        elif calificacion >= 5.0:
            categoria = 'average'
        elif calificacion >= 3.0:
            categoria = 'needs_improvement'
        else:
            categoria = 'poor'
        
        # Seleccionar plantilla base según categoría
        import random
        plantilla_base = random.choice(self.code_feedback_templates[categoria])
        
        # Personalizar comentario según estilo de aprendizaje
        comentario_personalizado = ""
        if estilo_aprendizaje:
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            if 'visual' in estilos:
                comentario_personalizado += "Te recomiendo utilizar diagramas de flujo o UML para visualizar la estructura de tu código antes de implementarlo."
                
            if 'auditivo' in estilos:
                comentario_personalizado += " Considera explicar tu código en voz alta o discutirlo con otros programadores para reforzar tu comprensión."
                
            if 'kinestesico' in estilos:
                comentario_personalizado += " Te beneficiaría experimentar con diferentes implementaciones y probar tu código con diversos casos de prueba."
                
            if 'lectura_escritura' in estilos:
                comentario_personalizado += " Continúa documentando tu código detalladamente y consultando la documentación oficial y ejemplos escritos."
        
        # Incorporar fortalezas y debilidades
        comentario_fortalezas = ""
        if fortalezas:
            comentario_fortalezas = "\n\nFortalezas destacadas:\n- " + "\n- ".join(fortalezas[:3])
            
        comentario_debilidades = ""
        if debilidades:
            comentario_debilidades = "\n\nAspectos a mejorar:\n- " + "\n- ".join(debilidades[:3])
        
        # Construir comentario completo
        comentario_completo = f"{plantilla_base}\n\n"
        
        if comentario_personalizado:
            comentario_completo += f"Considerando tu estilo de aprendizaje: {comentario_personalizado}\n"
            
        comentario_completo += f"{comentario_fortalezas}{comentario_debilidades}"
        
        return comentario_completo
    
    def _generar_sugerencias_mejora(self, calificacion, contenido, titulo, objetivo, debilidades, estilo_aprendizaje):
        """Genera sugerencias específicas para mejorar el contenido textual."""
        sugerencias = []
        
        # Sugerencias basadas en debilidades
        for debilidad in debilidades[:3]:  # Limitar a las 3 principales debilidades
            if "claridad" in debilidad.lower():
                sugerencias.append("Mejora la claridad utilizando ejemplos concretos y explicaciones más detalladas.")
            elif "profundidad" in debilidad.lower() or "superficial" in debilidad.lower():
                sugerencias.append("Profundiza en el análisis investigando más fuentes y desarrollando argumentos más complejos.")
            elif "estructura" in debilidad.lower() or "organización" in debilidad.lower():
                sugerencias.append("Mejora la estructura utilizando párrafos con una idea principal clara y transiciones lógicas entre secciones.")
            elif "originalidad" in debilidad.lower() or "creativ" in debilidad.lower():
                sugerencias.append("Incorpora perspectivas más originales o enfoques innovadores sobre el tema.")
            elif "relevancia" in debilidad.lower():
                sugerencias.append(f"Asegúrate de que todo el contenido esté directamente relacionado con el tema: '{titulo}'. Revisa el objetivo: '{objetivo}'.")
            elif "breve" in debilidad.lower():
                sugerencias.append("Desarrolla más extensamente el tema, incluyendo más ejemplos y explicaciones detalladas.")
            elif "vocabulario" in debilidad.lower():
                sugerencias.append("Enriquece tu vocabulario utilizando términos más precisos y variados.")
        
        # Sugerencias generales según calificación
        if calificacion < 5.0:
            sugerencias.append("Revisa los conceptos fundamentales del tema y asegúrate de comprenderlos correctamente.")
            sugerencias.append("Considera reescribir completamente el trabajo siguiendo una estructura más clara.")
        elif calificacion < 7.0:
            sugerencias.append("Revisa la coherencia entre párrafos para asegurar una progresión lógica de ideas.")
            sugerencias.append("Incluye más referencias o ejemplos para respaldar tus argumentos.")
        else:
            sugerencias.append("Para mejorar aún más, considera incorporar perspectivas críticas o comparativas.")
            sugerencias.append("Refuerza tus conclusiones conectándolas claramente con los puntos principales desarrollados.")
        
        # Sugerencias personalizadas según estilo de aprendizaje
        if estilo_aprendizaje:
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            if 'visual' in estilos:
                sugerencias.append("Intenta crear mapas conceptuales o diagramas antes de escribir para organizar mejor tus ideas.")
                
            if 'auditivo' in estilos:
                sugerencias.append("Considera grabar tus ideas en audio y luego escucharlas para refinar tu argumentación.")
                
            if 'kinestesico' in estilos:
                sugerencias.append("Relaciona los conceptos teóricos con experiencias prácticas o ejemplos concretos que hayas experimentado.")
                
            if 'lectura_escritura' in estilos:
                sugerencias.append("Practica escribiendo resúmenes de tus lecturas para mejorar tu capacidad de síntesis.")
        
        # Formatear sugerencias
        sugerencias_texto = "Para mejorar tu trabajo:\n\n- " + "\n- ".join(sugerencias[:5])  # Limitar a 5 sugerencias
        
        return sugerencias_texto
    
    def _generar_sugerencias_mejora_codigo(self, calificacion, codigo, titulo, objetivo, debilidades, estilo_aprendizaje):
        """Genera sugerencias específicas para mejorar el código."""
        sugerencias = []
        
        # Sugerencias basadas en debilidades
        for debilidad in debilidades[:3]:  # Limitar a las 3 principales debilidades
            if "funcionalidad" in debilidad.lower():
                sugerencias.append("Verifica que tu código cumpla con todos los requisitos funcionales y realiza pruebas exhaustivas.")
            elif "eficiencia" in debilidad.lower() or "optimiz" in debilidad.lower():
                sugerencias.append("Optimiza tu código identificando operaciones redundantes o algoritmos ineficientes.")
            elif "estilo" in debilidad.lower() or "legibilidad" in debilidad.lower():
                sugerencias.append("Mejora la legibilidad siguiendo convenciones de estilo como PEP 8 para Python o las guías de estilo oficiales del lenguaje.")
            elif "documentación" in debilidad.lower() or "comentarios" in debilidad.lower():
                sugerencias.append("Añade comentarios explicativos y docstrings para funciones y clases, describiendo parámetros, retornos y comportamiento.")
            elif "modularización" in debilidad.lower() or "funciones" in debilidad.lower():
                sugerencias.append("Refactoriza tu código en funciones más pequeñas y cohesivas con responsabilidades bien definidas.")
            elif "extenso" in debilidad.lower():
                sugerencias.append("Simplifica tu código eliminando redundancias y considerando patrones de diseño más eficientes.")
            elif "problema" in debilidad.lower() or "objetivo" in debilidad.lower():
                sugerencias.append(f"Asegúrate de que tu código resuelve específicamente el problema planteado: '{objetivo}'.")
        
        # Sugerencias generales según calificación
        if calificacion < 5.0:
            sugerencias.append("Revisa los conceptos fundamentales de programación y la lógica de tu solución.")
            sugerencias.append("Considera reescribir el código desde cero con un enfoque más estructurado.")
        elif calificacion < 7.0:
            sugerencias.append("Implementa manejo de errores y validación de entradas para hacer tu código más robusto.")
            sugerencias.append("Revisa la eficiencia de tus algoritmos y estructuras de datos elegidas.")
        else:
            sugerencias.append("Para mejorar aún más, considera implementar pruebas unitarias para verificar la funcionalidad.")
            sugerencias.append("Optimiza el rendimiento analizando la complejidad temporal y espacial de tu solución.")
        
        # Sugerencias personalizadas según estilo de aprendizaje
        if estilo_aprendizaje:
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            if 'visual' in estilos:
                sugerencias.append("Utiliza diagramas de flujo o UML para visualizar la estructura de tu código antes de implementarlo.")
                
            if 'auditivo' in estilos:
                sugerencias.append("Explica tu código en voz alta mientras lo escribes para detectar inconsistencias lógicas.")
                
            if 'kinestesico' in estilos:
                sugerencias.append("Practica implementando diferentes soluciones al mismo problema y compara su eficiencia.")
                
            if 'lectura_escritura' in estilos:
                sugerencias.append("Documenta tu proceso de desarrollo y las decisiones de diseño que tomas.")
        
        # Formatear sugerencias
        sugerencias_texto = "Para mejorar tu código:\n\n- " + "\n- ".join(sugerencias[:5])  # Limitar a 5 sugerencias
        
        return sugerencias_texto
    
    def _recomendar_recursos(self, estilo_aprendizaje, titulo, objetivo, calificacion):
        """Recomienda recursos educativos según el estilo de aprendizaje y tema."""
        recursos = []
        
        # Determinar categoría temática
        categoria = self._determinar_categoria_tematica(titulo, objetivo)
        
        # Si no hay estilo de aprendizaje definido, recomendar recursos variados
        if not estilo_aprendizaje:
            # Seleccionar recursos variados
            for estilo in ['visual', 'auditivo', 'kinestesico', 'lectura_escritura']:
                if categoria in self.recursos_educativos[estilo]:
                    # Seleccionar un recurso aleatorio de cada estilo
                    import random
                    recurso = random.choice(self.recursos_educativos[estilo][categoria])
                    recursos.append(recurso)
        else:
            # Seleccionar recursos según estilos de aprendizaje del estudiante
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            for estilo in estilos:
                if estilo in self.recursos_educativos and categoria in self.recursos_educativos[estilo]:
                    # Seleccionar hasta 2 recursos por estilo
                    import random
                    recursos_estilo = self.recursos_educativos[estilo][categoria]
                    num_recursos = min(2, len(recursos_estilo))
                    seleccion = random.sample(recursos_estilo, num_recursos)
                    recursos.extend(seleccion)
        
        # Si no se encontraron recursos específicos, recomendar recursos generales
        if not recursos:
            recursos_generales = [
                {"titulo": "Khan Academy - Cursos gratuitos en línea", "url": "https://es.khanacademy.org/"},
                {"titulo": "Coursera - Cursos universitarios en línea", "url": "https://www.coursera.org/"},
                {"titulo": "edX - Cursos en línea de universidades de élite", "url": "https://www.edx.org/"},
                {"titulo": "MIT OpenCourseWare - Materiales de cursos gratuitos", "url": "https://ocw.mit.edu/"}
            ]
            import random
            recursos = random.sample(recursos_generales, min(3, len(recursos_generales)))
        
        # Limitar a máximo 5 recursos
        return recursos[:5]
    
    def _generar_respuesta_irrelevante(self, estilo_aprendizaje, titulo, objetivo):
        """Genera una respuesta para contenido irrelevante al tema."""
        import random
        plantilla = random.choice(self.feedback_templates['irrelevant'])
        
        comentario = f"{plantilla}\n\n"
        comentario += f"El tema solicitado era: '{titulo}'\n"
        if objetivo:
            comentario += f"Con el objetivo: '{objetivo}'\n"
        
        comentario += "\nPor favor, revisa cuidadosamente los requisitos de la actividad y asegúrate de que tu trabajo aborde directamente el tema solicitado."
        
        # Sugerencias personalizadas según estilo de aprendizaje
        if estilo_aprendizaje:
            comentario += "\n\nConsiderando tu estilo de aprendizaje, te recomiendo:"
            estilos = [e.strip().lower() for e in estilo_aprendizaje.split(',')]
            
            if 'visual' in estilos:
                comentario += "\n- Crear un mapa conceptual del tema solicitado antes de comenzar a escribir."
                
            if 'auditivo' in estilos:
                comentario += "\n- Discutir el tema con compañeros o explicarlo en voz alta para clarificar tu comprensión."
                
            if 'kinestesico' in estilos:
                comentario += "\n- Relacionar el tema con experiencias prácticas o ejemplos concretos."
                
            if 'lectura_escritura' in estilos:
                comentario += "\n- Tomar notas detalladas sobre el tema antes de comenzar a escribir."
        
        # Recomendar recursos
        recursos = self._recomendar_recursos(estilo_aprendizaje, titulo, objetivo, 0.0)
        
        # Crear métricas vacías
        metricas = {
            'relevancia': 0.0,
            'claridad': 0.0,
            'profundidad': 0.0,
            'estructura': 0.0,
            'originalidad': 0.0
        }
        
        # Crear fortalezas y debilidades vacías
        fortalezas = []
        debilidades = ["El contenido no es relevante para el tema solicitado"]
        
        return {
            "calificacion": 0.0,
            "comentarios": comentario,
            "sugerencias": "Revisa cuidadosamente el tema y objetivo de la actividad antes de volver a intentarlo.",
            "relevancia": 0.0,
            "tipo_contenido": "texto",  # Añadir tipo_contenido
            "metricas": self._formatear_metricas(metricas, "texto"),  # Añadir métricas formateadas
            "fortalezas": fortalezas,  # Añadir fortalezas
            "debilidades": debilidades,  # Añadir debilidades
            "recursos_recomendados": recursos
        }
    
    def _formatear_metricas(self, metricas, tipo_contenido):
        """Formatea las métricas para presentación."""
        metricas_formateadas = {}
        
        for clave, valor in metricas.items():
            if isinstance(valor, float):
                if clave == 'relevancia':
                    # Convertir relevancia a porcentaje
                    metricas_formateadas[clave] = f"{valor * 100:.1f}%"
                else:
                    # Redondear a un decimal
                    metricas_formateadas[clave] = f"{valor:.1f}/10"
            else:
                metricas_formateadas[clave] = str(valor)
        
        return metricas_formateadas
    
    def entrenar_modelo(self, entradas, salidas, epochs=50, batch_size=8, validation_split=0.2):
        """
        Entrena el modelo con nuevos datos.
        
        Args:
            entradas: Lista de textos de entrada
            salidas: Lista de calificaciones (0-10)
            epochs: Número de épocas de entrenamiento
            batch_size: Tamaño del lote para entrenamiento
            validation_split: Proporción de datos para validación
            
        Returns:
            Diccionario con resultados del entrenamiento
        """
        if len(entradas) != len(salidas):
            raise ValueError("Las listas de entradas y salidas deben tener la misma longitud")
            
        if len(entradas) < 5:
            raise ValueError("Se necesitan al menos 5 ejemplos para entrenar el modelo")
        
        try:
            # Preprocesar textos
            textos_procesados = [self._preprocess_text(texto) for texto in entradas]
            
            # Actualizar vectorizador
            self.vectorizer.fit(textos_procesados)
            
            # Crear conjuntos de datos
            dataset = TextDataset(textos_procesados, salidas, self.vectorizer)
            
            # Dividir en entrenamiento y validación
            from torch.utils.data import random_split
            val_size = max(1, int(len(dataset) * validation_split))
            train_size = len(dataset) - val_size
            train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
            
            # Crear dataloaders
            from torch.utils.data import DataLoader
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=batch_size)
            
            # Entrenar modelo de contenido
            self.modelo_contenido.train()
            optimizer = self.optimizer_contenido
            
            # Inicializar variables de seguimiento
            mejor_val_loss = float('inf')
            epocas_sin_mejora = 0
            mejor_modelo_state = None
            
            # Historial de entrenamiento
            historial = {
                'train_loss': [],
                'val_loss': []
            }
            
            # Bucle de entrenamiento
            for epoch in range(epochs):
                # Entrenamiento
                self.modelo_contenido.train()
                train_loss = 0.0
                for inputs, targets in train_loader:
                    inputs, targets = inputs.to(self.device), targets.to(self.device)
                    
                    # Forward pass
                    outputs = self.modelo_contenido(inputs)
                    loss = self.criterion(outputs['global'].squeeze(), targets)
                    
                    # Backward y optimización
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    train_loss += loss.item()
                
                train_loss /= len(train_loader)
                historial['train_loss'].append(train_loss)
                
                # Validación
                self.modelo_contenido.eval()
                val_loss = 0.0
                with torch.no_grad():
                    for inputs, targets in val_loader:
                        inputs, targets = inputs.to(self.device), targets.to(self.device)
                        outputs = self.modelo_contenido(inputs)
                        loss = self.criterion(outputs['global'].squeeze(), targets)
                        val_loss += loss.item()
                
                val_loss /= len(val_loader)
                historial['val_loss'].append(val_loss)
                
                # Guardar mejor modelo
                if val_loss < mejor_val_loss:
                    mejor_val_loss = val_loss
                    mejor_modelo_state = self.modelo_contenido.state_dict().copy()
                    epocas_sin_mejora = 0
                else:
                    epocas_sin_mejora += 1
                
                # Early stopping
                if epocas_sin_mejora >= 10:
                    logger.info(f"Early stopping en época {epoch+1}")
                    break
                
                logger.info(f"Época {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            # Cargar el mejor modelo
            if mejor_modelo_state:
                self.modelo_contenido.load_state_dict(mejor_modelo_state)
            
            # Entrenar modelo de código (similar al anterior)
            # Por simplicidad, usamos los mismos datos para entrenar ambos modelos
            self.modelo_codigo.train()
            optimizer = self.optimizer_codigo
            
            # Inicializar variables de seguimiento
            mejor_val_loss = float('inf')
            epocas_sin_mejora = 0
            
            # Bucle de entrenamiento para modelo de código
            for epoch in range(epochs):
                # Entrenamiento
                self.modelo_codigo.train()
                train_loss = 0.0
                for inputs, targets in train_loader:
                    inputs, targets = inputs.to(self.device), targets.to(self.device)
                    
                    # Forward pass
                    outputs = self.modelo_codigo(inputs)
                    loss = self.criterion(outputs['global'].squeeze(), targets)
                    
                    # Backward y optimización
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    train_loss += loss.item()
                
                train_loss /= len(train_loader)
                
                # Validación
                self.modelo_codigo.eval()
                val_loss = 0.0
                with torch.no_grad():
                    for inputs, targets in val_loader:
                        inputs, targets = inputs.to(self.device), targets.to(self.device)
                        outputs = self.modelo_codigo(inputs)
                        loss = self.criterion(outputs['global'].squeeze(), targets)
                        val_loss += loss.item()
                
                val_loss /= len(val_loader)
                
                # Early stopping
                if val_loss < mejor_val_loss:
                    mejor_val_loss = val_loss
                    mejor_modelo_state = self.modelo_codigo.state_dict().copy()
                    epocas_sin_mejora = 0
                else:
                    epocas_sin_mejora += 1
                
                if epocas_sin_mejora >= 10:
                    logger.info(f"Early stopping en época {epoch+1}")
                    break
                
                logger.info(f"Código - Época {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            # Cargar el mejor modelo
            if mejor_modelo_state:
                self.modelo_codigo.load_state_dict(mejor_modelo_state)
            
            # Guardar modelos
            self.guardar_modelos()
            
            return {
                'status': 'success',
                'epochs_completed': epoch + 1,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'best_val_loss': mejor_val_loss,
                'historial': historial
            }
            
        except Exception as e:
            logger.error(f"Error en entrenamiento: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                'status': 'error',
                'message': str(e)
            }